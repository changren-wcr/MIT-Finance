0
00:00:00,000 --> 00:00:00,540


1
00:00:00,540 --> 00:00:04,260
PROFESSOR: So what does random walk model consist of?

2
00:00:04,260 --> 00:00:07,030
It's a sum of IID random variables.

3
00:00:07,030 --> 00:00:11,460
IID means independent and identically distributed.

4
00:00:11,460 --> 00:00:14,460
By independent, we mean that the z1, z2,

5
00:00:14,460 --> 00:00:17,580
z3 are independent random variables like two

6
00:00:17,580 --> 00:00:20,250
different dice, two different flips of a coin,

7
00:00:20,250 --> 00:00:22,630
or two different coins entirely.

8
00:00:22,630 --> 00:00:26,430
So the individual z's have nothing to do with each other.

9
00:00:26,430 --> 00:00:29,580
But we are putting them together in a particular sequence.

10
00:00:29,580 --> 00:00:32,340
Identically distributed means that they

11
00:00:32,340 --> 00:00:34,650
each are drawn from the same probability

12
00:00:34,650 --> 00:00:37,030
distribution no surprise there.

13
00:00:37,030 --> 00:00:40,470
What are the attributes of this sum ST where I take

14
00:00:40,470 --> 00:00:44,310
it to be z1, plus z2, plus z3?

15
00:00:44,310 --> 00:00:46,620
Because the variables are independent,

16
00:00:46,620 --> 00:00:50,580
the values that we have don't depend on--

17
00:00:50,580 --> 00:00:52,470
the new values that get added don't

18
00:00:52,470 --> 00:00:54,120
depend on the previous history.

19
00:00:54,120 --> 00:00:57,720
So each new increment can be added independently

20
00:00:57,720 --> 00:00:59,980
of what came before.

21
00:00:59,980 --> 00:01:02,160
The other thing is the importance

22
00:01:02,160 --> 00:01:03,990
of the identically distributed part

23
00:01:03,990 --> 00:01:07,020
is-- it means that the evolution in time is uniform.

24
00:01:07,020 --> 00:01:09,180
And we call this property stationarity.

25
00:01:09,180 --> 00:01:14,380
It doesn't mean that the model is static.

26
00:01:14,380 --> 00:01:16,260
It doesn't mean it's deterministic.

27
00:01:16,260 --> 00:01:19,800
All it means is that if we look at the values between any two

28
00:01:19,800 --> 00:01:22,620
points in time, the properties depend only

29
00:01:22,620 --> 00:01:24,420
on the differences in the point in time,

30
00:01:24,420 --> 00:01:26,920
not on some absolute point in time.

31
00:01:26,920 --> 00:01:32,340
So any given three-step period is going to be equivalent.

32
00:01:32,340 --> 00:01:33,840
One of the things we're going to see

33
00:01:33,840 --> 00:01:36,120
that's fascinating about the random walk model

34
00:01:36,120 --> 00:01:38,610
are some of its aspects of universality.

35
00:01:38,610 --> 00:01:40,080
There are a lot of features of it

36
00:01:40,080 --> 00:01:42,780
that are really independent of the micro-level.

37
00:01:42,780 --> 00:01:44,280
And that's going to be interesting

38
00:01:44,280 --> 00:01:45,630
for us starting out right now.

39
00:01:45,630 --> 00:01:47,130
And it's going to be something we'll

40
00:01:47,130 --> 00:01:50,340
take advantage of when we take the limit of this model

41
00:01:50,340 --> 00:01:54,310
to go to continuous time a little bit later in the course.

42
00:01:54,310 --> 00:01:58,140
So it's easy to generalize for financial applications.

43
00:01:58,140 --> 00:02:00,600
This bare-bones model is going to be a little bit simple.

44
00:02:00,600 --> 00:02:04,410
But hang on a very short time, and we'll add in two parameters

45
00:02:04,410 --> 00:02:06,180
to make it useful for finance.

46
00:02:06,180 --> 00:02:08,669
The random walk appears in many other contexts

47
00:02:08,669 --> 00:02:12,360
in applied mathematics, and physics, and engineering.

48
00:02:12,360 --> 00:02:15,622
And it's the building block for more complex models.

49
00:02:15,622 --> 00:02:17,580
So we're going to start to get to know it well.

50
00:02:17,580 --> 00:02:18,872
Then we'll see how to build it.

51
00:02:18,872 --> 00:02:22,150
Although this model doesn't have any memory of the past,

52
00:02:22,150 --> 00:02:24,640
we'll see that models that do have

53
00:02:24,640 --> 00:02:27,150
interesting non-trivial causal structure

54
00:02:27,150 --> 00:02:30,450
can be expressed in terms of building blocks

55
00:02:30,450 --> 00:02:35,090
that do come from what we'll see in the random walk model.

56
00:02:35,090 --> 00:02:36,850
So what we're going to do is we're

57
00:02:36,850 --> 00:02:39,680
going to start with the simplest of all random variables.

58
00:02:39,680 --> 00:02:42,100
We'll call these standardized random variables,

59
00:02:42,100 --> 00:02:44,440
and we'll denote them by the letter z.

60
00:02:44,440 --> 00:02:46,060
And they've got these properties.

61
00:02:46,060 --> 00:02:48,700
First, they're mean is 0.

62
00:02:48,700 --> 00:02:50,170
So these are unbiased.

63
00:02:50,170 --> 00:02:52,450
They're equally likely to be positive or negative.

64
00:02:52,450 --> 00:02:54,940
The average value is 0.

65
00:02:54,940 --> 00:02:56,980
Their variance is 1.

66
00:02:56,980 --> 00:03:01,750
So they have a standard amount of randomness, a standard step

67
00:03:01,750 --> 00:03:03,550
size for these given increments.

68
00:03:03,550 --> 00:03:08,050
And for our independence part, the correlation

69
00:03:08,050 --> 00:03:10,660
of any two random variables taken at different points

70
00:03:10,660 --> 00:03:12,490
in time is 0.

71
00:03:12,490 --> 00:03:15,730
So we can summarize these three properties symbolically

72
00:03:15,730 --> 00:03:16,780
in this box.

73
00:03:16,780 --> 00:03:22,390
We've got that the expectation of z is 0.

74
00:03:22,390 --> 00:03:25,900
The expectation of z squared is the variance.

75
00:03:25,900 --> 00:03:28,180
Remember that the variance is the expectation

76
00:03:28,180 --> 00:03:30,970
of the square minus the square of the expectation.

77
00:03:30,970 --> 00:03:32,590
The expectation is 0.

78
00:03:32,590 --> 00:03:35,240
So expectation of z squared is the variance.

79
00:03:35,240 --> 00:03:36,400
It's equal to 1.

80
00:03:36,400 --> 00:03:41,680
And, because z of t and z of t prime,

81
00:03:41,680 --> 00:03:43,720
if t and t prime are two different times,

82
00:03:43,720 --> 00:03:46,000
are two independent random variables,

83
00:03:46,000 --> 00:03:48,732
the expectation of the product is equal to 0.

84
00:03:48,732 --> 00:03:50,440
And this is the same as their correlation

85
00:03:50,440 --> 00:03:51,580
when they have mean 0.

86
00:03:51,580 --> 00:03:54,250
And remember for independent random variables,

87
00:03:54,250 --> 00:03:56,410
the expectation of a product is the product

88
00:03:56,410 --> 00:03:57,640
of the expectations.

89
00:03:57,640 --> 00:03:59,320
Each of the expectations is 0.

90
00:03:59,320 --> 00:04:01,810
0 times 0 is 0.

91
00:04:01,810 --> 00:04:04,630
So what are some examples z's that we could use?

92
00:04:04,630 --> 00:04:05,620
This is all we need.

93
00:04:05,620 --> 00:04:08,390
We only need the things that we have here in this box.

94
00:04:08,390 --> 00:04:11,860
So one example, the classic random walk,

95
00:04:11,860 --> 00:04:13,390
is something like a coin toss.

96
00:04:13,390 --> 00:04:15,710
We take a step to the left, to the right.

97
00:04:15,710 --> 00:04:16,310
We go up.

98
00:04:16,310 --> 00:04:17,329
We go down.

99
00:04:17,329 --> 00:04:20,899
We move plus 1 or minus 1 with equal probability.

100
00:04:20,899 --> 00:04:25,476
So we can model that with the discrete random variable, zt.

101
00:04:25,476 --> 00:04:29,510
zt takes values plus or minus 1 with equal probability.

102
00:04:29,510 --> 00:04:33,940
Obviously, it satisfies these properties in the box above.

103
00:04:33,940 --> 00:04:39,560
Another example is a continuous z, a Gaussian random variable.

104
00:04:39,560 --> 00:04:41,540
This one is also going to be normalized.

105
00:04:41,540 --> 00:04:45,640
So zt is drawn from an N 0, 1 distribution with mean 0,

106
00:04:45,640 --> 00:04:46,720
variance 1.

107
00:04:46,720 --> 00:04:48,640
And it's probability distribution

108
00:04:48,640 --> 00:04:50,860
is the usual Gaussian form normalized.

109
00:04:50,860 --> 00:04:55,120
So e to the minus z squared over 2 is the probability density.

110
00:04:55,120 --> 00:04:58,090
The expectation is 0 because this is an even function.

111
00:04:58,090 --> 00:05:00,550
And to show that its variance is equal to 1

112
00:05:00,550 --> 00:05:04,730
involves doing a definite integral.

113
00:05:04,730 --> 00:05:06,820
So everything that we're about to see

114
00:05:06,820 --> 00:05:10,100
would be true with either of these variables.

115
00:05:10,100 --> 00:05:13,270
Notice that they're quite different in detail

116
00:05:13,270 --> 00:05:16,330
that the first one, the discrete one,

117
00:05:16,330 --> 00:05:19,460
will only allow our sum to have discrete values.

118
00:05:19,460 --> 00:05:22,360
The second one is continuously distributed.

119
00:05:22,360 --> 00:05:24,880
Our trick-- and we're going to be coming back to this again

120
00:05:24,880 --> 00:05:25,750
and again--

121
00:05:25,750 --> 00:05:29,240
is that, when we're interested in a sum of random variables--

122
00:05:29,240 --> 00:05:31,600
this is our S of T--

123
00:05:31,600 --> 00:05:35,080
we're not going to ask for the full probability distribution.

124
00:05:35,080 --> 00:05:37,750
We're only going to ask for the mean and the variance.

125
00:05:37,750 --> 00:05:40,150
We're only going to ask for the individual moments.

126
00:05:40,150 --> 00:05:42,760
And the detailed distribution could

127
00:05:42,760 --> 00:05:45,970
be complicated in the case of the plus or minus 1.

128
00:05:45,970 --> 00:05:47,650
We have a binomial distribution.

129
00:05:47,650 --> 00:05:49,658
It's easy to work out the combinatorics.

130
00:05:49,658 --> 00:05:51,700
It's a lot more work than what we're going to do.

131
00:05:51,700 --> 00:05:55,240
And we're not going to need the more fine grained detail

132
00:05:55,240 --> 00:05:56,680
of all the higher moments.

133
00:05:56,680 --> 00:05:58,120
For the Gaussian random variable,

134
00:05:58,120 --> 00:06:00,850
it's kind of a special case because, as you may know,

135
00:06:00,850 --> 00:06:04,210
the sum of Gaussian random variables is Gaussian.

136
00:06:04,210 --> 00:06:06,160
So there's some special results there.

137
00:06:06,160 --> 00:06:09,070
But any z that satisfies these properties

138
00:06:09,070 --> 00:06:10,875
will work for what we're about to see.

139
00:06:10,875 --> 00:06:11,500
So what's that?

140
00:06:11,500 --> 00:06:13,360
Let's take a look.

141
00:06:13,360 --> 00:06:15,920
We'll consider the sum of random variables.

142
00:06:15,920 --> 00:06:18,850
ST is z1 plus, z2, plus z3.

143
00:06:18,850 --> 00:06:22,300
And we're not going to ask about the distribution of S of T.

144
00:06:22,300 --> 00:06:24,950
But we're going to ask about its mean and its variance.

145
00:06:24,950 --> 00:06:26,890
So what about the mean?

146
00:06:26,890 --> 00:06:31,810
For the mean of the sum, ST, We have a very simple result.

147
00:06:31,810 --> 00:06:34,630
Remember that expectation is a linear operator.

148
00:06:34,630 --> 00:06:37,420
That means that the expectation of a sum

149
00:06:37,420 --> 00:06:42,040
is the sum of the expectations so the expectation of ST

150
00:06:42,040 --> 00:06:45,835
is the expectation of z1, plus the expectation z2, plus da,

151
00:06:45,835 --> 00:06:49,870
da, da, da, up to the expectation of the final one.

152
00:06:49,870 --> 00:06:52,870
Since each of these expectations is equal to 0,

153
00:06:52,870 --> 00:06:55,780
your sum is equal to 0, no surprise

154
00:06:55,780 --> 00:06:57,350
there really if you think about it.

155
00:06:57,350 --> 00:06:58,450
This is unbiased.

156
00:06:58,450 --> 00:07:01,050
We add together a bunch of unbiased random variables.

157
00:07:01,050 --> 00:07:03,970
The mean value is the same as the value of each of them.

158
00:07:03,970 --> 00:07:05,400
It's 0.

159
00:07:05,400 --> 00:07:06,400
What about the variance?

160
00:07:06,400 --> 00:07:08,440
The variance a little more interesting.

161
00:07:08,440 --> 00:07:12,190
So for the variance, we have the expectation of S squared.

162
00:07:12,190 --> 00:07:17,140
Again, we're able to simplify this because S has mean 0.

163
00:07:17,140 --> 00:07:19,570
So let's just plug it in.

164
00:07:19,570 --> 00:07:22,060
Expand out this quadratic.

165
00:07:22,060 --> 00:07:25,960
So the term in parentheses z1, plus z2, plus zT,

166
00:07:25,960 --> 00:07:30,760
all the way up is S of T. We take the square.

167
00:07:30,760 --> 00:07:34,460
Let's expand that quadratic, and we get two kinds terms.

168
00:07:34,460 --> 00:07:35,770
And then we apply linearity.

169
00:07:35,770 --> 00:07:38,800
That is, for each of the terms, the expectation of the sum

170
00:07:38,800 --> 00:07:40,420
is the sum of the expectations.

171
00:07:40,420 --> 00:07:42,070
So we have two kinds of terms.

172
00:07:42,070 --> 00:07:44,920
We have these squared terms whereas z1

173
00:07:44,920 --> 00:07:46,840
gets multiplied times z1.

174
00:07:46,840 --> 00:07:49,540
And I have these terms here, which

175
00:07:49,540 --> 00:07:54,520
are the expectation of one of z's with itself, z1 squared,

176
00:07:54,520 --> 00:07:56,350
z2 squared, z3 squared.

177
00:07:56,350 --> 00:07:57,850
And I have T of these.

178
00:07:57,850 --> 00:07:59,770
And I could have the cross terms,

179
00:07:59,770 --> 00:08:04,780
where I have z1 with z2, z2 with z3, z4 with z7, and so on.

180
00:08:04,780 --> 00:08:06,460
Each of those appear twice.

181
00:08:06,460 --> 00:08:09,950
There are T choose 2 of those terms.

182
00:08:09,950 --> 00:08:15,460
But wonderfully in this product, each of these is equal to 0.

183
00:08:15,460 --> 00:08:20,740
So every single term in this second sum is equal to 0.

184
00:08:20,740 --> 00:08:24,700
And the first consists of T terms, each of which

185
00:08:24,700 --> 00:08:26,410
is equal to 1.

186
00:08:26,410 --> 00:08:31,210
So the result is the variance of ST,

187
00:08:31,210 --> 00:08:34,840
the sum of the random variables, is equal to T.

188
00:08:34,840 --> 00:08:40,360
So here's our basic result. The mean of the random walk is 0.

189
00:08:40,360 --> 00:08:43,570
The variance of the random walk grows linearly

190
00:08:43,570 --> 00:08:45,130
with the number of steps.

191
00:08:45,130 --> 00:08:47,050
And the standard deviation, which

192
00:08:47,050 --> 00:08:49,120
is the square root of the variance,

193
00:08:49,120 --> 00:08:54,610
grows with the square root of T. Let's summarize.

194
00:08:54,610 --> 00:08:57,010
The random walk model is constructed

195
00:08:57,010 --> 00:08:59,450
as a sum of IID random variables.

196
00:08:59,450 --> 00:09:01,060
We take a bunch of z's.

197
00:09:01,060 --> 00:09:02,350
We put them together.

198
00:09:02,350 --> 00:09:04,300
And S1 is z1.

199
00:09:04,300 --> 00:09:06,010
S2 is z1 plus z2.

200
00:09:06,010 --> 00:09:09,400
S3 is z1, plus z2, plus z3, and so on.

201
00:09:09,400 --> 00:09:11,680
It's a simple example of a discrete time

202
00:09:11,680 --> 00:09:13,540
stochastic process.

203
00:09:13,540 --> 00:09:17,530
Rather than asking for the complete distribution of ST,

204
00:09:17,530 --> 00:09:18,850
we ask about the moments.

205
00:09:18,850 --> 00:09:20,620
We ask about the mean and the variance.

206
00:09:20,620 --> 00:09:23,410
And those are computed very easily by linearity.

207
00:09:23,410 --> 00:09:24,790
The mean is 0.

208
00:09:24,790 --> 00:09:27,520
The variance is proportional to the number of steps.

209
00:09:27,520 --> 00:09:31,690
And we've done this all using standardized random variable z.

210
00:09:31,690 --> 00:09:33,160
They could be continuous, discrete.

211
00:09:33,160 --> 00:09:35,350
They could be anything that satisfies

212
00:09:35,350 --> 00:09:36,910
these basic standard properties.

213
00:09:36,910 --> 00:09:40,210
Namely, the expectation of z is 0.

214
00:09:40,210 --> 00:09:42,520
The variance of z is 1.

215
00:09:42,520 --> 00:09:45,130
And the expectation of two different z's

216
00:09:45,130 --> 00:09:48,870
taken at two different times is equal to 0.

