0
00:00:00,000 --> 00:00:01,965


1
00:00:01,965 --> 00:00:03,590
PROFESSOR: When we look at forecasting,

2
00:00:03,590 --> 00:00:06,690
there are a number of different elements that come into play.

3
00:00:06,690 --> 00:00:09,420
And I would just like to lay them out for you.

4
00:00:09,420 --> 00:00:12,050
But we're only going to take a look at a small subset of them.

5
00:00:12,050 --> 00:00:14,210
Forecasting is a very big subject.

6
00:00:14,210 --> 00:00:16,910
We're just going to touch on it in the context of time series

7
00:00:16,910 --> 00:00:18,860
modeling applications, so that we

8
00:00:18,860 --> 00:00:21,500
can see how we take the structure of our time series

9
00:00:21,500 --> 00:00:25,220
model and construct specific forecasts based

10
00:00:25,220 --> 00:00:29,320
on given information sets.

11
00:00:29,320 --> 00:00:31,970
So what are the elements of forecasting generally?

12
00:00:31,970 --> 00:00:34,860
Well first, we'd like to know the nature of the process.

13
00:00:34,860 --> 00:00:36,560
Is it something deterministic?

14
00:00:36,560 --> 00:00:40,530
If it's given by a known curve, a sine wave or parabola,

15
00:00:40,530 --> 00:00:42,780
we can predict exactly where something is going to be.

16
00:00:42,780 --> 00:00:45,560
We can tell exactly when the next eclipse of the sun

17
00:00:45,560 --> 00:00:46,278
is going to be.

18
00:00:46,278 --> 00:00:48,320
We know exactly when the next eclipse of the moon

19
00:00:48,320 --> 00:00:49,160
is going to be.

20
00:00:49,160 --> 00:00:53,337
We can even send spaceships to land very precisely,

21
00:00:53,337 --> 00:00:54,920
or send them through the solar system,

22
00:00:54,920 --> 00:00:57,950
because we have deterministic processes that we can solve.

23
00:00:57,950 --> 00:01:00,860
If we have random processes, we don't expect

24
00:01:00,860 --> 00:01:02,270
to get that kind of precision.

25
00:01:02,270 --> 00:01:07,280
We're going to have necessarily probabilistic forecasts.

26
00:01:07,280 --> 00:01:09,110
The processes could be stationary,

27
00:01:09,110 --> 00:01:10,850
they could be non-stationary.

28
00:01:10,850 --> 00:01:13,670
We're going to have very different tools for predicting

29
00:01:13,670 --> 00:01:14,870
them in those cases.

30
00:01:14,870 --> 00:01:18,140
And are they laws of nature or are they human behavior?

31
00:01:18,140 --> 00:01:19,730
They're laws of nature, at least we

32
00:01:19,730 --> 00:01:22,370
know that the process itself doesn't depend

33
00:01:22,370 --> 00:01:27,270
on circumstances around it--

34
00:01:27,270 --> 00:01:31,170
human behavior could change at any time.

35
00:01:31,170 --> 00:01:33,980
How much do we know about the process?

36
00:01:33,980 --> 00:01:36,200
Do we know the process, or do we not know

37
00:01:36,200 --> 00:01:38,030
what the underlying process is?

38
00:01:38,030 --> 00:01:40,280
Perhaps we know the process.

39
00:01:40,280 --> 00:01:43,340
We know what it is, let's say, an AR(1) process,

40
00:01:43,340 --> 00:01:46,790
or an ARMA(1,2) process, but we don't know what the parameters

41
00:01:46,790 --> 00:01:47,640
are.

42
00:01:47,640 --> 00:01:49,340
So in one case, we have to figure out

43
00:01:49,340 --> 00:01:50,720
what model to work with.

44
00:01:50,720 --> 00:01:54,500
In the other case, we may have uncertain estimates

45
00:01:54,500 --> 00:01:56,660
of the parameters which we'd like to apply.

46
00:01:56,660 --> 00:01:58,280
And that will be an additional source

47
00:01:58,280 --> 00:02:01,610
of uncertainty in our forecasts compared to the case where

48
00:02:01,610 --> 00:02:04,130
we know the parameters.

49
00:02:04,130 --> 00:02:06,230
And is this a theoretical model that's

50
00:02:06,230 --> 00:02:08,780
based on some financial or economic ideas?

51
00:02:08,780 --> 00:02:12,180
Or is it an empirical model that's just fit to the data,

52
00:02:12,180 --> 00:02:14,210
and it seems to work.

53
00:02:14,210 --> 00:02:17,340
Or is it a theoretical model that should work?

54
00:02:17,340 --> 00:02:20,840
We have the sort of normative and positive views of things.

55
00:02:20,840 --> 00:02:22,700
And although the approach is going

56
00:02:22,700 --> 00:02:24,890
to be the same, in the way in which we'll

57
00:02:24,890 --> 00:02:27,980
think about evaluating the model quality will be different,

58
00:02:27,980 --> 00:02:30,650
because to the extent that we observe deviations,

59
00:02:30,650 --> 00:02:32,840
it will tell us something about our assumptions

60
00:02:32,840 --> 00:02:34,430
and what we would need to revisit,

61
00:02:34,430 --> 00:02:36,440
and how we would then refine things.

62
00:02:36,440 --> 00:02:38,480
If it's an empirical model, we may

63
00:02:38,480 --> 00:02:40,820
need to get more data or a better data set,

64
00:02:40,820 --> 00:02:43,250
or we might need to find a better model to fit it.

65
00:02:43,250 --> 00:02:45,890
If we have a mismatch with a theoretical model,

66
00:02:45,890 --> 00:02:47,660
perhaps we need new ideas.

67
00:02:47,660 --> 00:02:50,480
Perhaps the ideas that we thought controlled

68
00:02:50,480 --> 00:02:53,990
the processes to produce the variables

69
00:02:53,990 --> 00:02:56,900
were just wrong or in need of some extension

70
00:02:56,900 --> 00:02:59,820
and generalization.

71
00:02:59,820 --> 00:03:01,200
How complex is the model?

72
00:03:01,200 --> 00:03:02,850
The examples we're doing are mostly

73
00:03:02,850 --> 00:03:06,010
going to be univariate models or bivariate models.

74
00:03:06,010 --> 00:03:09,150
So we could have a very large number of variables.

75
00:03:09,150 --> 00:03:10,530
And they could be coupled.

76
00:03:10,530 --> 00:03:13,470
Typically, when we think about multivariate models,

77
00:03:13,470 --> 00:03:17,160
we look for ways that we can simplify them and reduce them

78
00:03:17,160 --> 00:03:18,940
to previous cases.

79
00:03:18,940 --> 00:03:22,140
So it's often possible by taking linear combinations,

80
00:03:22,140 --> 00:03:25,350
to take a multivariate process, particularly if it's

81
00:03:25,350 --> 00:03:28,350
a linear model, and reduce it to a series

82
00:03:28,350 --> 00:03:32,400
of uncoupled separate linear models that then we can solve.

83
00:03:32,400 --> 00:03:33,930
But the techniques will depend.

84
00:03:33,930 --> 00:03:37,530
And linear is usually a fairly straightforward category

85
00:03:37,530 --> 00:03:40,590
with some reliable tools that we can regularly deploy.

86
00:03:40,590 --> 00:03:44,700
Non-linear is kind of an open category where there's

87
00:03:44,700 --> 00:03:47,250
no guarantee of success, and there's not necessarily

88
00:03:47,250 --> 00:03:48,420
a general approach.

89
00:03:48,420 --> 00:03:50,067
Those are not the most common models

90
00:03:50,067 --> 00:03:51,150
that we'll see in finance.

91
00:03:51,150 --> 00:03:52,733
And those will not be among the things

92
00:03:52,733 --> 00:03:56,160
we'll be looking at in our future discussions

93
00:03:56,160 --> 00:04:00,750
or in any of the problems and applications.

94
00:04:00,750 --> 00:04:02,670
We do want to think about what the horizon is.

95
00:04:02,670 --> 00:04:04,310
Do we need one step ahead?

96
00:04:04,310 --> 00:04:06,120
Do we need multiple steps ahead?

97
00:04:06,120 --> 00:04:07,590
That is, would we like to produce

98
00:04:07,590 --> 00:04:10,080
at every possible future horizon?

99
00:04:10,080 --> 00:04:11,970
Does it go off to infinity?

100
00:04:11,970 --> 00:04:15,120
Do we need asymptotic results as t goes to infinity?

101
00:04:15,120 --> 00:04:17,880
Or perhaps, as many financial applications,

102
00:04:17,880 --> 00:04:18,990
we have a finite date.

103
00:04:18,990 --> 00:04:21,820
We have the maturity date for a bond.

104
00:04:21,820 --> 00:04:24,670
We have the ending period for a loan.

105
00:04:24,670 --> 00:04:27,030
We have the expiration date for an option.

106
00:04:27,030 --> 00:04:29,910
And in those cases, we might be interested in forecasts

107
00:04:29,910 --> 00:04:33,120
over only a multiple steps, but maybe only

108
00:04:33,120 --> 00:04:37,260
over a particular horizon, which decreases as time evolves.

109
00:04:37,260 --> 00:04:40,390


110
00:04:40,390 --> 00:04:42,220
What are the forecast criteria?

111
00:04:42,220 --> 00:04:46,210
Are we actually forecasting observable variables or not?

112
00:04:46,210 --> 00:04:47,390
That might seem strange.

113
00:04:47,390 --> 00:04:50,380
You might think, of course we forecast observable variables.

114
00:04:50,380 --> 00:04:53,380
But keep in mind, that one of the things we've already seen

115
00:04:53,380 --> 00:04:56,530
is models where we introduce volatility as a parameter.

116
00:04:56,530 --> 00:04:57,800
We have sigma.

117
00:04:57,800 --> 00:05:01,480
And if we take a model of time varying volatility,

118
00:05:01,480 --> 00:05:05,200
we need to keep in mind that volatility--

119
00:05:05,200 --> 00:05:07,450
while it can be a parameter in a model--

120
00:05:07,450 --> 00:05:09,580
is not an observable quantity.

121
00:05:09,580 --> 00:05:11,890
We can ask what the price of an asset is.

122
00:05:11,890 --> 00:05:15,190
We can't ask what it's instantaneous volatility is.

123
00:05:15,190 --> 00:05:17,560
To know it's volatility, we need to observe it

124
00:05:17,560 --> 00:05:18,850
over a period of time.

125
00:05:18,850 --> 00:05:21,110
We measure the random fluctuations.

126
00:05:21,110 --> 00:05:23,470
And that quantifies what the volatility is.

127
00:05:23,470 --> 00:05:26,170
But if we have a model of dynamic volatility,

128
00:05:26,170 --> 00:05:28,850
where the volatility changes over time--

129
00:05:28,850 --> 00:05:31,090
there are many such models, they're

130
00:05:31,090 --> 00:05:32,740
very important in finance--

131
00:05:32,740 --> 00:05:36,380
but we can't directly observe the volatility.

132
00:05:36,380 --> 00:05:38,860
So we need to do some extra work to be

133
00:05:38,860 --> 00:05:42,280
able to connect the predictions of the model with things

134
00:05:42,280 --> 00:05:45,250
that we can observe so that we can compare predictions

135
00:05:45,250 --> 00:05:48,340
to outcomes, so that we can compare forecasts

136
00:05:48,340 --> 00:05:50,270
to observations.

137
00:05:50,270 --> 00:05:53,530
We'll want to think about measures of forecast accuracy.

138
00:05:53,530 --> 00:05:56,200
How close is close enough?

139
00:05:56,200 --> 00:05:59,620
If we insist on a point forecast being exactly right,

140
00:05:59,620 --> 00:06:02,960
most of our predictions are going to be exactly wrong.

141
00:06:02,960 --> 00:06:05,180
But usually, we'd like to have some measure.

142
00:06:05,180 --> 00:06:08,050
And one of the important things to keep in mind in finance

143
00:06:08,050 --> 00:06:11,080
compared to other areas where we use statistical methods,

144
00:06:11,080 --> 00:06:13,330
and we make predictions, and we make forecasts,

145
00:06:13,330 --> 00:06:16,480
is that we often have a very real cost associated

146
00:06:16,480 --> 00:06:17,570
with error.

147
00:06:17,570 --> 00:06:19,960
So the usual things in literature,

148
00:06:19,960 --> 00:06:21,790
like mean squared forecast error,

149
00:06:21,790 --> 00:06:23,590
are convenient mathematically.

150
00:06:23,590 --> 00:06:24,970
They're somewhat intuitive.

151
00:06:24,970 --> 00:06:29,920
But in finance, we often have other numbers in mind,

152
00:06:29,920 --> 00:06:33,160
like the loss in a particular scenario--

153
00:06:33,160 --> 00:06:36,100
the financial loss, which might not be the same easy

154
00:06:36,100 --> 00:06:37,780
to use mathematical expression.

155
00:06:37,780 --> 00:06:41,920
But we do want to keep track of the fact that the economic cost

156
00:06:41,920 --> 00:06:44,650
of an error, or a deviation, or the benefit--

157
00:06:44,650 --> 00:06:47,470
if it's deviations on the upside--

158
00:06:47,470 --> 00:06:49,810
is something that we can directly

159
00:06:49,810 --> 00:06:53,110
measure and is directly related to issues of valuation.

160
00:06:53,110 --> 00:06:55,930
So we'll often want to think about forecast accuracy--

161
00:06:55,930 --> 00:06:59,140
weighting things by their financial importance,

162
00:06:59,140 --> 00:07:01,480
not just taking an equal weighted average

163
00:07:01,480 --> 00:07:03,580
across all possible kinds of errors.

164
00:07:03,580 --> 00:07:06,910
We might want to weight more heavily the kinds of errors

165
00:07:06,910 --> 00:07:08,815
that we're most interested in avoiding.

166
00:07:08,815 --> 00:07:13,530


167
00:07:13,530 --> 00:07:15,000
Models don't stay the same.

168
00:07:15,000 --> 00:07:16,140
Models change.

169
00:07:16,140 --> 00:07:18,370
Models need to be replaced.

170
00:07:18,370 --> 00:07:21,270
So we want to think about what kind of model evolution

171
00:07:21,270 --> 00:07:22,930
we might expect.

172
00:07:22,930 --> 00:07:28,560
We can have static parameters that stay fixed,

173
00:07:28,560 --> 00:07:31,260
or we might think about having adjustable parameters

174
00:07:31,260 --> 00:07:33,630
that maybe we change over time.

175
00:07:33,630 --> 00:07:36,660
We might think about models where, when we see errors,

176
00:07:36,660 --> 00:07:39,090
we update our parameters, so that we

177
00:07:39,090 --> 00:07:44,010
can make gradual changes to our model as our dataset increases.

178
00:07:44,010 --> 00:07:46,380
As we make more observations, we can improve

179
00:07:46,380 --> 00:07:48,090
our estimates of parameters.

180
00:07:48,090 --> 00:07:53,010
And we may need to think also about identifying situations

181
00:07:53,010 --> 00:07:55,290
where we would declare our model to be broken.

182
00:07:55,290 --> 00:07:57,850
There's some fundamental change in the market,

183
00:07:57,850 --> 00:08:00,570
sometimes called a regime shift or a break

184
00:08:00,570 --> 00:08:02,800
in time series, that's telling us,

185
00:08:02,800 --> 00:08:04,470
hey, that model is not working.

186
00:08:04,470 --> 00:08:07,290
There's something new generating the data.

187
00:08:07,290 --> 00:08:09,420
Someone swapped out one roulette wheel for us,

188
00:08:09,420 --> 00:08:10,800
and they put in another one.

189
00:08:10,800 --> 00:08:13,660
So those are kind of things we want to be aware of.

190
00:08:13,660 --> 00:08:15,960
There's a question, is the model completely static?

191
00:08:15,960 --> 00:08:18,670
Is it somewhat dynamic where the parameters get updated?

192
00:08:18,670 --> 00:08:20,790
And if so, how and when?

193
00:08:20,790 --> 00:08:24,540
And then, when is it time to go shopping for a new model?

194
00:08:24,540 --> 00:08:29,790


195
00:08:29,790 --> 00:08:32,340
How do we set up forecasts?

196
00:08:32,340 --> 00:08:36,720
Well, typically we start with observations up

197
00:08:36,720 --> 00:08:38,760
to some particular time t.

198
00:08:38,760 --> 00:08:42,360
Now, we can't really go for the infinite past.

199
00:08:42,360 --> 00:08:44,340
And hopefully, none of our results

200
00:08:44,340 --> 00:08:47,520
would depend on the series existing in the infinite past.

201
00:08:47,520 --> 00:08:49,830
But what we usually think about for forecasting

202
00:08:49,830 --> 00:08:51,390
is there is some amount of history

203
00:08:51,390 --> 00:08:53,400
up to a particular point.

204
00:08:53,400 --> 00:08:57,390
And maybe we have some set of observations x0, x1, x2, x3,

205
00:08:57,390 --> 00:08:58,950
up to the time xt.

206
00:08:58,950 --> 00:09:01,110
And my convention for forecasting

207
00:09:01,110 --> 00:09:03,420
will be t will be the time at which we're

208
00:09:03,420 --> 00:09:07,530
making our forecast about future values for t

209
00:09:07,530 --> 00:09:10,710
plus 1, t plus 2, all the way up through t plus h, where

210
00:09:10,710 --> 00:09:12,760
h stands for the horizon.

211
00:09:12,760 --> 00:09:15,150
And we assume, that we have the information set

212
00:09:15,150 --> 00:09:19,470
available of everything that happened before and possibly

213
00:09:19,470 --> 00:09:21,930
including the current observation.

214
00:09:21,930 --> 00:09:24,670
And we want to know what happens next.

215
00:09:24,670 --> 00:09:26,940
The probabilities that we're interested in computing

216
00:09:26,940 --> 00:09:28,967
are going to be conditional probabilities.

217
00:09:28,967 --> 00:09:31,050
But it's really the same thing we've already seen.

218
00:09:31,050 --> 00:09:32,640
We're taking expectations.

219
00:09:32,640 --> 00:09:35,430
The only difference is, we need to look at the time index

220
00:09:35,430 --> 00:09:37,380
and not apply stationarity directly.

221
00:09:37,380 --> 00:09:39,390
We can apply stationarity for things

222
00:09:39,390 --> 00:09:40,500
that are random variables.

223
00:09:40,500 --> 00:09:43,560
That is, we can say that the probability

224
00:09:43,560 --> 00:09:46,650
distributions of future realizations are the same.

225
00:09:46,650 --> 00:09:49,800
But that does not mean the past draws from the distribution

226
00:09:49,800 --> 00:09:51,630
are the same.

227
00:09:51,630 --> 00:09:54,120
Even though a head and a tail are equally likely,

228
00:09:54,120 --> 00:09:57,000
or one of the six sides of a die are equally likely,

229
00:09:57,000 --> 00:10:00,150
on our next five random occurrences,

230
00:10:00,150 --> 00:10:03,490
the last five are fixed, because they are what they are.

231
00:10:03,490 --> 00:10:07,290
So that's our distinction between past and future.

232
00:10:07,290 --> 00:10:09,210
We can look at making point forecasts,

233
00:10:09,210 --> 00:10:12,600
and we can think about whether we can have enough information

234
00:10:12,600 --> 00:10:16,110
to generate a full probability distribution for future events,

235
00:10:16,110 --> 00:10:18,090
or perhaps somewhere in between.

236
00:10:18,090 --> 00:10:20,370
Not just a number, but perhaps moments

237
00:10:20,370 --> 00:10:21,960
of the future distribution.

238
00:10:21,960 --> 00:10:22,680
What's the mean?

239
00:10:22,680 --> 00:10:23,820
What's the variance?

240
00:10:23,820 --> 00:10:26,910
And that could tell us something about what our confidence is

241
00:10:26,910 --> 00:10:29,955
and what a confidence interval is around

242
00:10:29,955 --> 00:10:34,350
a forecast for future values.

243
00:10:34,350 --> 00:10:36,780
We can sometimes include subjective information

244
00:10:36,780 --> 00:10:38,910
as well in a Bayesian approach, where

245
00:10:38,910 --> 00:10:42,030
we take information about what our prior beliefs are

246
00:10:42,030 --> 00:10:43,260
as a starting point.

247
00:10:43,260 --> 00:10:46,140
And then, we iteratively update our forecasts

248
00:10:46,140 --> 00:10:48,480
as new information becomes available.

249
00:10:48,480 --> 00:10:51,300
And we do it in a way that's consistent with the laws

250
00:10:51,300 --> 00:10:52,170
of probability.

251
00:10:52,170 --> 00:10:56,530


252
00:10:56,530 --> 00:10:58,930
The optimal forecast we can think

253
00:10:58,930 --> 00:11:01,210
of from a result of Granger as simply

254
00:11:01,210 --> 00:11:04,720
being the forecast at horizon, h,

255
00:11:04,720 --> 00:11:07,300
is the conditional mean of the forecast.

256
00:11:07,300 --> 00:11:11,080
That's our best forecast, provided that the cost function

257
00:11:11,080 --> 00:11:13,510
is symmetric and convex.

258
00:11:13,510 --> 00:11:19,180
So this says that the forecast for a future variable

259
00:11:19,180 --> 00:11:23,170
is, we take its expectation based on what we know now.

260
00:11:23,170 --> 00:11:25,400
We can also compute other moments around it.

261
00:11:25,400 --> 00:11:28,630
But for the point forecast, this is the best forecast

262
00:11:28,630 --> 00:11:33,730
that we can do in terms of minimizing different error

263
00:11:33,730 --> 00:11:34,940
criteria.

264
00:11:34,940 --> 00:11:38,570
So for a given model, we can use the optimal forecast.

265
00:11:38,570 --> 00:11:40,960
And for a given set of data, we're

266
00:11:40,960 --> 00:11:44,500
tasked with finding what the optimal model is.

267
00:11:44,500 --> 00:11:47,860
If we think of a typical kind of random walk-- in this case,

268
00:11:47,860 --> 00:11:49,720
an arithmetic random walk--

269
00:11:49,720 --> 00:11:52,540
where I have a price, and each time

270
00:11:52,540 --> 00:11:57,190
is the previous price plus some new innovation, some new event

271
00:11:57,190 --> 00:11:58,785
that comes along, something with step

272
00:11:58,785 --> 00:12:02,380
size sigma where z is a normalized random variable.

273
00:12:02,380 --> 00:12:05,230
Sigma is the scale of the volatility.

274
00:12:05,230 --> 00:12:09,610
And we ask, what's my forecast h steps

275
00:12:09,610 --> 00:12:13,780
ahead for the value of the price that follows this forecast?

276
00:12:13,780 --> 00:12:18,970
What I do is, I iterate this out to solve for p t plus h

277
00:12:18,970 --> 00:12:21,230
in terms of the previous t's.

278
00:12:21,230 --> 00:12:22,870
I take expectations.

279
00:12:22,870 --> 00:12:25,510
And because all I'm going to do is add together

280
00:12:25,510 --> 00:12:28,480
more z's, and those all have 0 mean,

281
00:12:28,480 --> 00:12:31,870
the expectation of p of t plus h-- given

282
00:12:31,870 --> 00:12:33,610
the information I have available--

283
00:12:33,610 --> 00:12:35,620
is the current price.

284
00:12:35,620 --> 00:12:40,690
That is, the forecast for the price h steps in the future

285
00:12:40,690 --> 00:12:41,980
is the current price.

286
00:12:41,980 --> 00:12:44,410
Now, for a symmetric random walk, that makes sense.

287
00:12:44,410 --> 00:12:47,560
We're equally likely to have disease go up or down.

288
00:12:47,560 --> 00:12:49,390
They will in general diffuse.

289
00:12:49,390 --> 00:12:50,800
They will move around.

290
00:12:50,800 --> 00:12:54,100
They're very unlikely to be exactly back where

291
00:12:54,100 --> 00:12:55,630
we started at p.

292
00:12:55,630 --> 00:12:59,340
Nevertheless, that is the optimal forecast.

